import streamlit as st
from educhain import Educhain, LLMConfig
from langchain_cerebras import ChatCerebras
from cerebras.cloud.sdk import Cerebras
import os
import json


st.set_page_config(page_title="AI Courtroom ‚Äî Mock Trials with Cerebras & Educhain", layout="wide")

st.title("‚öñÔ∏è AI Courtroom ‚öñÔ∏è")
st.markdown("<h3 style='font-size: 24px;'>üë®‚Äç‚öñÔ∏èJudge , ‚öîÔ∏è Prosecutor , üõ°Ô∏èDefense , üë§ Defendant and  üìú The Verdict üî®</h3>", unsafe_allow_html=True)
st.markdown("_Use a real case URL from Wikipedia, news, or a court report to begin._")
st.divider()
# Sidebar: API key input
with st.sidebar:
    st.markdown(
        "<div style='text-align: center; margin: 2px 0;'>"
        "<a href='https://www.buildfastwithai.com/' target='_blank' style='text-decoration: none;'>"
        "<div style='border: 2px solid #e0e0e0; border-radius: 6px; padding: 4px; "
        "background: linear-gradient(145deg, #ffffff, #f5f5f5); "
        "box-shadow: 0 2px 6px rgba(0,0,0,0.1); "
        "transition: all 0.3s ease; display: inline-block; width: 100%;'>"
        "<img src='https://github.com/Shubhwithai/chat-with-qwen/blob/main/company_logo.png?raw=true' "
        "style='width: 100%; max-width: 100%; height: auto; border-radius: 8px; display: block;' "
        "alt='Build Fast with AI Logo'>"
        "</div></a></div>", unsafe_allow_html=True
    )
    st.header("Configuration")
    CEREBRAS_API_KEY = st.text_input("Enter your Cerebras API Key", type="password")
    use_comedic = st.selectbox("Courtroom style", ["Serious", "Dramatic", "Comedic"])
    num_facts = st.slider("Number of case facts/questions (Educhain)", min_value=1, max_value=10, value=9)
    st.markdown(" Model: `gpt-oss-120b` (Cerebras)")
    st.markdown("---")
    st.markdown("""<div class="sidebar-footer">
                    <p>‚ù§Ô∏è Built by <a href="https://buildfastwithai.com" target="_blank">Build Fast with AI</a></p>
                </div> """, unsafe_allow_html=True)
# Initialize Educhain only after user provides API key ‚Äî we will initialize the ChatCerebras wrapper for Educhain
if CEREBRAS_API_KEY:
    # Initialize Cerebras SDK client for direct calls (feedback, verdict structured output)
    cerebras_client = Cerebras(api_key=CEREBRAS_API_KEY)

    # Initialize Educhain with a Cerebras-backed LLM via langchain_cerebras
    # NOTE: this requires the `langchain_cerebras` adapter and Educhain to accept LLMConfig
    try:
        llm = ChatCerebras(model="gpt-oss-120b", api_key=CEREBRAS_API_KEY)
    except TypeError:
        # Some wrappers take api key via environment
        os.environ["CEREBRAS_API_KEY"] = CEREBRAS_API_KEY
        llm = ChatCerebras(model="gpt-oss-120b")

    cerebras_llm_config = LLMConfig(custom_model=llm)
    client = Educhain(cerebras_llm_config)
else:
    cerebras_client = None
    client = None

# Main UI: case URL input
st.subheader("1. Paste a case report URL")
case_url = st.text_input("Case report URL (Wikipedia / news link / case study link)",)

if st.button("Ingest case & generate facts"):
    if not case_url:
        st.error("Please paste a valid URL first.")
    elif not client:
        st.error("Enter your Cerebras API key in the sidebar so the app can initialize Cerebras + Educhain.")
    else:
        with st.spinner("Fetching case and generating facts via Educhain..."):
            try:
                custom_instructions = (
                    "Generate {num} concise factual statements or True/False style facts about the legal case at the given URL. "
                    "These facts should be usable as evidence or arguments in a courtroom roleplay. Keep them intermediate difficulty and numbered."
                )

                # Use Educhain to extract a small set of facts / Qs from the URL
                facts = client.qna_engine.generate_questions_from_data(
                    source=case_url,
                    source_type="url",
                    num=num_facts,
                    question_type="True/False",
                    difficulty_level="Intermediate",
                    custom_instructions=custom_instructions
                )

                try:
                    facts_list = facts.model_dump_json()
                except Exception:
                    # fallback: try casting to str
                    facts_list = str(facts)

                st.success("Facts generated by Educhain ‚Äî used as case evidence below.")
                st.subheader("Case Evidence (Educhain output)")
                st.code(facts_list, language="json")

                try:
                    parsed_facts = json.loads(facts_list)
                    formatted_facts = json.dumps(parsed_facts, indent=2)
                except Exception:
                    formatted_facts = str(facts_list)

                st.session_state["case_facts"] = formatted_facts

                st.session_state["case_url"] = case_url

            except Exception as e:
                st.error(f"Educhain failed to generate facts: {e}")

# Show quick action: Run Mock Trial
st.subheader("2. Run the Trial")
proceed = st.button("Start Trial (Cerebras will roleplay)")
if proceed:
    if "case_facts" not in st.session_state:
        st.error("Please ingest a case first using the button above.")
    elif not cerebras_client:
        st.error("Provide Cerebras API key in the sidebar.")
    else:
        facts_text = st.session_state["case_facts"]
        court_style = use_comedic

        # Prompt: Markdown output for entire trial
        system_prompt = (
            "You are a courtroom simulation engine. Roles: Judge, Prosecutor, Defense Lawyer, Defendant, and Jury. "
            f"Tone: {court_style}.\n"
            "Use the provided case facts as admissible evidence. Play out a full trial including:\n"
            "- Opening statements\n"
            "- Witness/evidence discussion (use provided facts as evidence)\n"
            "- Cross-examination\n"
            "- Closing statements\n"
            "- Final verdict announcement\n\n"
            "IMPORTANT:\n"
            "1. Output EVERYTHING in well-formatted **Markdown**.\n"
            "2. Use headings for sections (## Opening Statements, ## Evidence, etc.).\n"
            "3. Bold speaker names (e.g. **Judge:**) at the start of each dialogue line.\n"
            "4. Use bullet points for lists of evidence.\n"
            "5. At the very end, include a '## Final Verdict' section with:\n"
            "   - Verdict: ...\n"
            "   - Sentence: ...\n"
            "   - Reasoning Summary: ...\n"
        )

        user_prompt = (
            f"Case URL: {st.session_state.get('case_url', '(unknown)')}\n\n"
            f"Case Facts / Evidence (JSON format):\n{facts_text}\n\n"
            "Each fact has a 'question' (statement) and an 'explanation'. "
            "Use the 'question' for courtroom statements, and the 'explanation' for reasoning when presenting evidence.\n"
            "Begin the trial now. Judge speaks first."
        )

        with st.spinner("Cerebras is simulating the courtroom..."):
            try:
                trial_resp = cerebras_client.chat.completions.create(
                    model="gpt-oss-120b",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    reasoning_effort="high",
                    max_completion_tokens=7000,
                    temperature=0.9,
                    top_p=1.0
                )

                # Get Markdown transcript
                transcript_md = trial_resp.choices[0].message.content.strip()

                st.subheader("Courtroom Transcript (Markdown)")
                st.markdown(transcript_md)

                # Save to session state
                st.session_state["last_transcript"] = transcript_md

            except Exception as e:
                st.error(f"Cerebras call failed: {e}")
